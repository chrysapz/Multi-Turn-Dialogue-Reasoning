{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371a0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab7161d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_mapping = {\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3\n",
    "}\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, sample_id, answer, options, article, generated_utterances=None):\n",
    "        self.sample_id = sample_id\n",
    "        self.answer = answer\n",
    "        self.options = options\n",
    "        self.article = article\n",
    "        \n",
    "        self.label_descr = options[answer_mapping[answer]]\n",
    "        \n",
    "        self.generated_utterances = generated_utterances or []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Sample ID: {self.sample_id}\\nAnswer Number: {self.answer}\\nAnswer: {self.label_descr}\\nOptions: {self.options}\\nContext: {self.article}\"\n",
    "\n",
    "def load_sample_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.loads(file.read())\n",
    "    return Sample(\n",
    "        data['id'],\n",
    "        data['answers'],\n",
    "        data['options'],\n",
    "        data['article']\n",
    "    )\n",
    "\n",
    "def load_all_samples(base_dir,mode):\n",
    "    data_dir = os.path.join(base_dir, mode)\n",
    "    samples = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            sample = load_sample_from_file(os.path.join(data_dir, filename))\n",
    "            samples.append(sample)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49b154ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_averages(samples):\n",
    "    total_word_count = 0\n",
    "    total_sentences = 0\n",
    "    total_turns = 0\n",
    "\n",
    "    for sample in samples:\n",
    "        # average sentence length for the responses\n",
    "        for option in sample.options:\n",
    "            total_word_count += len(option.split())\n",
    "            total_sentences += 1\n",
    "\n",
    "        # average turns in a conversation\n",
    "        turns = sample.article.split('.')\n",
    "        total_turns += len([t for t in turns if t.strip()])  # Filtering out any empty turns\n",
    "\n",
    "    avg_sentence_length = total_word_count / total_sentences\n",
    "    avg_turns = total_turns / len(samples)\n",
    "\n",
    "    return avg_sentence_length, avg_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61626e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ID: train_1\n",
      "Answer Number: B\n",
      "Answer: f : although the suit you sew is the same as it , the material of this suit is imported from italy .\n",
      "Options: [\"f : no suit has the same style as it . it 's the style that makes it special . it is worth the price .\", 'f : although the suit you sew is the same as it , the material of this suit is imported from italy .', 'f : the material of this suit is imported from france , it makes the suit special .', 'f : but the color of our suit is very special .']\n",
      "Context: m : excuse me . how much is this suit ? f : it 's on sale today for $ 750 . it 's normally $ 900 . m : wow , that is pretty expensive ! i was thinking that it might be 4 or 500 . f : this material is imported from italy . it 's the finest in the world , and if you bought a suit made of this material at many department stores , you would pay about $ 2000 . m : uh-hah . but is n't that the point of coming to a market like this , to get a discount compared to the expensive department stores ? besides i saw a suit just like this one a few stalls down , and they were selling it for $ 600 . i still thought that it was too expensive .\n",
      "   \n",
      "Sample ID: train_10\n",
      "Answer Number: C\n",
      "Answer: m : okay , i 'll put candles on it right away . i think i will be a little tired after all this preparation for this birthday party .\n",
      "Options: ['m : when we finish making the birthday cake , we can start preparing for the birthday party .', 'm : oh , i forget it , cooking a huge dinner is not easy .', \"m : okay , i 'll put candles on it right away . i think i will be a little tired after all this preparation for this birthday party .\", \"m : the party is almost ready , but the food is not enough . let 's prepare some more .\"]\n",
      "Context: m : is everything ready for billy 's birthday party ? f : yes . i finished making the birthday cake and i put everything on the table . did you find the party hats ? m : yes , i did . i put one for each child on the table . i put up the big `` happy birthday '' sign , too . f : thanks , honey . do you think we have enough for the kids to eat and drink ? m : i 'm sure we do . here 's enough food to feed an army . f : that birthday cake looks beautiful , but you have n't put any candles on it yet .\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"data\\mutual\"\n",
    "train_samples = load_all_samples(base_dir, \"train\")\n",
    "\n",
    "for i in range(2):\n",
    "    print(train_samples[i])\n",
    "    print(\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "742d6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length of responses: 17.87 words\n",
      "Average turns per conversation: 6.66\n"
     ]
    }
   ],
   "source": [
    "avg_sentence_length, avg_turns = compute_averages(train_samples)\n",
    "\n",
    "print(f\"Average sentence length of responses: {avg_sentence_length:.2f} words\")\n",
    "print(f\"Average turns per conversation: {avg_turns:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84d9a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "def generate_utterances_for_sample(sample, num_sequences=3):\n",
    "   \n",
    "    input_text = sample.article\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(input_ids, max_length=400, num_return_sequences=num_sequences, pad_token_id=tokenizer.eos_token_id,\n",
    "                           num_beams=3,early_stopping=True)\n",
    "\n",
    "    generated_utterances = [tokenizer.decode(o) for o in output]\n",
    "    sample.generated_utterances = generated_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae7d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors:  42%|████████████████████▏                           | 640M/1.52G [25:18<34:50, 421kB/s]\n"
     ]
    }
   ],
   "source": [
    "def augment_samples(samples):\n",
    "    for sample in samples:\n",
    "        utterances = generate_utterances_for_sample(sample)\n",
    "        sample.generated_utterances = utterances\n",
    "\n",
    "augment_samples(train_samples)\n",
    "\n",
    "for sample in samples[:5]:\n",
    "    print(sample)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70953a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
